{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "#To load the data from disk into memory\n",
    "#review file imported\n",
    "with open(\"data/review_sample_cleveland.json\") as f:\n",
    "    reviews = f.read().strip().split(\"\\n\")\n",
    "    \n",
    "reviews = [json.loads(review) for review in reviews] \n",
    "reviews=reviews[:10000]\n",
    "#extracting stars and text in two different list for each review\n",
    "#We now have two arrays of data: the text of each review and the respective star-rating. \n",
    "#Our task is to train a system that can predict the star-rating from looking at only the review text\n",
    "texts = [review['text'] for review in reviews]\n",
    "stars = [review['stars'] for review in reviews]\n",
    "print len(texts)\n",
    "print len(stars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A complication is that our dataset is unbalanced. We have more examples of texts that typically have a 5-star rating than texts that typically have a 2-star rating. Because of the probabilistic models at the base of most machine learning classifiers, we’ll get less biased predictions if we train the system on balanced data. This means that ideally we should have the same number of examples of each review type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "def balance_classes(xs, ys):\n",
    "    \"\"\"Undersample xs, ys to balance classes.\"\"\"\n",
    "    freqs = Counter(ys)\n",
    "#creating a counter so that number of reviews in each category(1 star, 2 star etc) are equal \n",
    "# the least common class is the maximum number we want for all classes\n",
    "#In machine learning, it’s common to separate our data into features and labels. \n",
    "#In our case, the review texts (the input data) will be converted into features and the star ratings (what we are trying to predict) are the labels. \n",
    "#You’ll often see these two categories referred to as X and Y respectively. \n",
    "#Adding the following method to a cell will allow us to balance a dataset by removing over-represented samples from the two lists.\n",
    "    max_allowable = freqs.most_common()[-1][1]\n",
    "    num_added = {clss: 0 for clss in freqs.keys()}\n",
    "    new_ys = []\n",
    "    new_xs = []\n",
    "    for i, y in enumerate(ys):\n",
    "        if num_added[y] < max_allowable:\n",
    "            new_ys.append(y)\n",
    "            new_xs.append(xs[i])\n",
    "            num_added[y] += 1\n",
    "    return new_xs, new_ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({5: 3765, 4: 2704, 3: 1316, 1: 1307, 2: 908})\n",
      "Counter({1: 908, 2: 908, 3: 908, 4: 908, 5: 908})\n"
     ]
    }
   ],
   "source": [
    "print(Counter(stars))\n",
    "balanced_x, balanced_y = balance_classes(texts, stars)\n",
    "print(Counter(balanced_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see above that in the original distribution, we had 8074 2-star reviews and 36275 5-star reviews. After balancing, we have 8074 of each class of review. We’re now ready to prepare our data for classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectorising Data and creating Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Computers deal with numbers much better than they do with text, so we need a meaningful way to convert all the text data into matrices of numbers.\n",
    "\n",
    "### CountVectoriser: \n",
    "A straightforward (and oft-used) method for doing this is to count how often words appear in a piece of text and represent each text with an array of word-frequencies.The array would be quite large and sparse, containing one element for every possible word.\n",
    "\n",
    "### TF-IDF:\n",
    "A slightly more sophisticated approach would be to use Term Frequency Inverse Document Frequency (TF-IDF) vectors. This approach comes from the idea that most frequent words in individual texts are important to that text but most common words in entire dataset, such as 'the' aren’t very important, while less common words such as Namibia are more important. TF-IDF therefore normalises the count of each word in each text by the number of times that that word occurs in all of the texts. If a word occurs in nearly all of the texts, we deem it to be less significant. If it only appears in several texts, we regard it as more important."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### n-grams:\n",
    "Words often mean very different things when we combine them in different ways. We will expect our learning algorithm to learn that a review containing the words bad is likely to be negative, while one containing the word great is likely to be positive. However, reviews containing phrases such as “… and then they gave us a full refund. Not bad!” or “The food was not great” will trip up our system if it only considers words individually.\n",
    "\n",
    "When we break a text into n-grams, we consider several words grouped together to be a single word. “The food was not great” would be represented using bi-grams as (the food, food was, was not, not great), and this would allow our system to learn that not great is a typically negative statement because it appears in many negative reviews.\n",
    "\n",
    "For our analysis, we’ll stick with single words (also called unigrams) and bigrams (two words at a time)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF Vectoriser:\n",
    "Luckily scikit-learn implements all of this for us: the TF-IDF algorithm along with n-grams and tokenization (splitting the text into individual words). To turn all of our reviews into vectors, run the following code (which took roughly 22 minutes to complete on an intel core i5):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:00:02.389644\n",
      "(4540, 500)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from datetime import datetime\n",
    "# This vectorizer breaks text into single words and bi-grams\n",
    "# and then calculates the TF-IDF representation\n",
    "vectorizer = TfidfVectorizer(stop_words='english',max_features=500,ngram_range=(1,2))\n",
    "t1 = datetime.now()\n",
    "\n",
    "# the 'fit' builds up the vocabulary from all the reviews\n",
    "# while the 'transform' step turns each indivdual text into\n",
    "# a matrix of numbers.\n",
    "vectors = vectorizer.fit_transform(balanced_x)\n",
    "print(datetime.now() - t1)\n",
    "print vectors.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "#model to train 66% and test 33%\n",
    "X_train, X_test, y_train, y_test = train_test_split(vectors, balanced_y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The classifier we’ll use is a Linear Support Vector Machine (SVM), which has been shown to perform well on several text classifications tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:00:04.495602\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# initialise the SVM classifier\n",
    "classifier = SVC()\n",
    "\n",
    "# train the classifier\n",
    "t1 = datetime.now()\n",
    "classifier.fit(X_train, y_train)\n",
    "print(datetime.now() - t1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "next, The first line of the output displays the ratings our classifier predicted for the first ten reviews in our dataset,and the second line shows the actual ratings of the same reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n",
      "[4, 5, 5, 3, 4, 4, 2, 3, 4, 1]\n"
     ]
    }
   ],
   "source": [
    "preds = classifier.predict(X_test)\n",
    "print(list(preds[:10]))\n",
    "print(y_test[:10])\n",
    "# print (X_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.18345563709139426\n"
     ]
    }
   ],
   "source": [
    "#predicting accuracy score\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(y_test, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of nearest neighbor classifier on test set: 0.43\n"
     ]
    }
   ],
   "source": [
    "#knn classfrom sklearn.neighbors import KNeighborsClassifierifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=10)\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred = knn.predict(X_test)\n",
    "\n",
    "from sklearn import metrics\n",
    "print('Accuracy of nearest neighbor classifier on test set: {:.2f}'.format(knn.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import the class\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# instantiate the model (using the default parameters)\n",
    "logreg = LogisticRegression()\n",
    "\n",
    "# fit the model with data\n",
    "logreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of logistic regression classifier on test set: 0.51\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "y_pred = logreg.predict(X_test)\n",
    "print('Accuracy of logistic regression classifier on test set: {:.2f}'.format(logreg.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf=MultinomialNB()\n",
    "X_train,X_test,y_train,y_test= train_test_split(vectors, balanced_y,test_size=0.3,random_state=0)\n",
    "\n",
    "clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Multinomial on test set: 0.51\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "y_pred=clf.predict(X_test)\n",
    "print('Accuracy of Multinomial on test set: {:.2f}'.format(clf.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Classification Models\n",
    "names = []\n",
    "params = []\n",
    "results = []\n",
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of logistic regression classifier on test set: 0.51\n",
      "45.92511013215859\n",
      "{'penalty': 'l1', 'C': 1.0}\n"
     ]
    }
   ],
   "source": [
    "#Logistic Regression\n",
    "logreg = LogisticRegression()\n",
    "#model to train 66% and test 33%\n",
    "X_train, X_test, y_train, y_test = train_test_split(vectors, balanced_y, test_size=0.33, random_state=42)\n",
    "# fit the model with data\n",
    "logreg.fit(X_train, y_train)\n",
    "from sklearn import metrics\n",
    "y_pred = logreg.predict(X_test)\n",
    "print('Accuracy of logistic regression classifier on test set: {:.2f}'.format(logreg.score(X_test, y_test)))\n",
    "\n",
    "grid={\"C\":np.logspace(-3,3,7), \"penalty\":[\"l1\",\"l2\"]}# l1 lasso l2 ridge\n",
    "gd_sr = GridSearchCV(estimator=logreg,  \n",
    "                     param_grid=grid,\n",
    "                     scoring='accuracy',\n",
    "                     cv=4,\n",
    "                     n_jobs=-1)\n",
    "gd_sr.fit(vectors, balanced_y)\n",
    "results.append(100*gd_sr.best_score_)\n",
    "params.append(gd_sr.best_params_)\n",
    "names.append('logReg')\n",
    "print results[0]\n",
    "print params[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45.17621145374449\n",
      "{'C': 100.0}\n"
     ]
    }
   ],
   "source": [
    "#SVC\n",
    "grid_param = {'C': [1e0, 1e1, 1e2, 1e3]}\n",
    "from sklearn.svm import SVC\n",
    "clf3 = SVC()\n",
    "gd_sr = GridSearchCV(estimator=clf3,  \n",
    "                     param_grid=grid_param,\n",
    "                     scoring='accuracy',\n",
    "                     cv=4,\n",
    "                     n_jobs=-1)\n",
    "gd_sr.fit(vectors, balanced_y)\n",
    "results.append(100*gd_sr.best_score_)\n",
    "params.append(gd_sr.best_params_)\n",
    "names.append('SVC')\n",
    "print results[1]\n",
    "print params[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/sklearn/neighbors/base.py:212: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: \"\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/neighbors/base.py:212: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: \"\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/neighbors/base.py:212: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: \"\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/neighbors/base.py:212: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35.50660792951542\n",
      "{'n_neighbors': 10, 'leaf_size': 2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/sklearn/neighbors/base.py:212: UserWarning: cannot use tree with sparse input: using brute force\n",
      "  warnings.warn(\"cannot use tree with sparse input: \"\n"
     ]
    }
   ],
   "source": [
    "#KNN\n",
    "grid_param = {'n_neighbors':[3,10],\n",
    "          'leaf_size':[2,5]}\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "clf1 = KNeighborsClassifier(n_neighbors=3,algorithm='ball_tree')\n",
    "gd_sr = GridSearchCV(estimator=clf1,  \n",
    "                     param_grid=grid_param,\n",
    "                     scoring='accuracy',\n",
    "                     cv=4,\n",
    "                     n_jobs=-1)\n",
    "gd_sr.fit(vectors, balanced_y)\n",
    "results.append(100*gd_sr.best_score_)\n",
    "params.append(gd_sr.best_params_)\n",
    "names.append('KNN')\n",
    "print results[2]\n",
    "print params[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   models  accuracy\n",
      "0  logReg  45.92511\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEKCAYAAAAfGVI8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAETtJREFUeJzt3XuwXWV9xvHvI6hYsXKLDAUhKhSKVRAi4mC9AHYQrKIyoqKNFsXxSutdpAWtM+pQQXGkA0U0VouIF2DQQWMEFcRLIshdgyCKooQCKqIo5Nc/1opzOM3J2cGsvXPyfj8zZ7LXdf/O7JzznPd913pXqgpJUrvuN+kCJEmTZRBIUuMMAklqnEEgSY0zCCSpcQaBJDXOIJCkxhkEktQ4g0CSGrfxpAsYxVZbbVXz58+fdBmSNKcsW7bslqqaN9t+cyII5s+fz9KlSyddhiTNKUluGGU/u4YkqXEGgSQ1ziCQpMYZBJLUOINAkhpnEEhS4wwCSWqcQSBJjTMIJKlxc+LOYknrv30+tM+kS9jgXfS6iwY5ry0CSWqcQSBJjbNrSOuVn7zrMZMuYYO3/b9dPukStJ6xRSBJjTMIJKlxBoEkNc4gkKTGGQSS1DiDQJIaZxBIUuMMAklqnEEgSY0zCCSpcQaBJDXOIJCkxhkEktQ4g0CSGmcQSFLjDAJJapxBIEmNMwgkqXEGgSQ1bvAgSLJRkkuSnNsvPyLJt5Ncm+SMJA8YugZJ0szG0SI4Erh6yvL7gBOqakfgNuDwMdQgSZrBoEGQZDvgIODUfjnAvsBn+l0WAQcPWYMkac2GbhF8AHgLsLJf3hK4varu7pdvBLZd3YFJjkiyNMnSFStWDFymJLVrsCBI8kzg5qpadl+Or6pTqmpBVS2YN2/eOq5OkrTKxgOeex/gWUkOBDYB/hL4ILBZko37VsF2wM8GrEGSNIvBWgRV9faq2q6q5gMvAL5aVYcB5wOH9LstBM4eqgZJ0uwmcR/BW4E3JLmWbszgIxOoQZLUG7Jr6E+q6gLggv71dcBe43hfSdLsvLNYkhpnEEhS4wwCSWqcQSBJjTMIJKlxBoEkNc4gkKTGGQSS1DiDQJIaZxBIUuMMAklqnEEgSY0zCCSpcQaBJDXOIJCkxo3leQTjtOebPz7pEjZ4y477x0mXIGkdskUgSY0zCCSpcQaBJDXOIJCkxhkEktQ4g0CSGmcQSFLjDAJJapxBIEmNMwgkqXEGgSQ1ziCQpMYZBJLUOINAkhpnEEhS4wwCSWqcQSBJjTMIJKlxBoEkNc4gkKTGDRYESTZJ8p0k309yZZJ39usfkeTbSa5NckaSBwxVgyRpdkO2CO4C9q2q3YDdgQOS7A28DzihqnYEbgMOH7AGSdIsBguC6tzRL96//ypgX+Az/fpFwMFD1SBJmt2gYwRJNkpyKXAzsBj4EXB7Vd3d73IjsO2QNUiS1mzQIKiqe6pqd2A7YC9gl1GPTXJEkqVJlq5YsWKwGiWpdWO5aqiqbgfOB54IbJZk437TdsDPZjjmlKpaUFUL5s2bN44yJalJQ141NC/JZv3rBwFPB66mC4RD+t0WAmcPVYMkaXYbz77LfbYNsCjJRnSB8+mqOjfJVcCnkrwbuAT4yIA1SJJmMVgQVNVlwONWs/46uvECSdJ6wDuLJalxIwVBks8lOSiJwSFJG5hRf7GfBLwIWJ7kvUl2HrAmSdIYjRQEVfWVqjoM2AP4MfCVJN9M8rIk9x+yQEnSsEbu6kmyJfBS4OV0V/t8kC4YFg9SmSRpLEa6aijJ54Gdgf8G/qGqbuo3nZFk6VDFSZKGN+rloydW1fmr21BVC9ZhPZKkMRu1a2jXVXcJAyTZPMmrB6pJkjRGowbBK/r5ggCoqtuAVwxTkiRpnEYNgo2SZNVCP22ETxaTpA3AqGME59ENDJ/cL7+yXydJmuNGDYK30v3yf1W/vBg4dZCKJEljNVIQVNVK4D/7L0nSBmTU+wh2At4D7Apssmp9VT1yoLokSWMy6mDxR+laA3cDTwM+DnxiqKIkSeMzahA8qKqWAKmqG6rqWOCg4cqSJI3LqIPFd/VTUC9P8lq65wxvOlxZkqRxGbVFcCTwF8DrgT2BF9M9b1iSNMfN2iLobx47tKreBNwBvGzwqiRJYzNri6Cq7gGeNIZaJEkTMOoYwSVJzgHOBH67amVVfW6QqiRJYzNqEGwC/C+w75R1BRgEkjTHjXpnseMCkrSBGvXO4o/StQDupar+aZ1XJEkaq1G7hs6d8noT4DnAz9d9OZKkcRu1a+izU5eTnA5cOEhFkqSxGvWGsul2Ah62LguRJE3GqGMEv+HeYwS/oHtGgSRpjhu1a+ghQxciSZqMkbqGkjwnyUOnLG+W5ODhypIkjcuoYwTHVNWvVi1U1e3AMcOUJEkap1GDYHX7jXrpqSRpPTZqECxNcnySR/VfxwPLhixMkjQeowbB64A/AGcAnwJ+D7xmqKIkSeMz6lVDvwXeNnAtkqQJGPWqocVJNpuyvHmSLw1XliRpXEbtGtqqv1IIgKq6jVnuLE7y8CTnJ7kqyZVJjuzXb9EHy/L+383ve/mSpD/XqEGwMsn2qxaSzGc1s5FOczfwxqraFdgbeE2SXem6mJZU1U7AEuxykqSJGvUS0HcAFyb5GhDg74Aj1nRAVd0E3NS//k2Sq4FtgWcDT+13WwRcgNNVSNLEjDpYfF6SBXS//C8BzgJ+N+qb9C2IxwHfBrbuQwK6OYu2Xot6JUnr2KiTzr0cOBLYDriUrqvnYu796MqZjt0U+Czwz1X16yR/2lZVlWS1XUxJjqBvdWy//far20WStA6MOkZwJPB44IaqehrdX/e3r/kQSHJ/uhD45JQH3f8yyTb99m2Am1d3bFWdUlULqmrBvHnzRixTkrS2Rg2C31fV7wGSPLCqrgF2XtMB6f70/whwdVUdP2XTOcDC/vVC4Oy1K1mStC6NOlh8Y38fwVnA4iS3ATfMcsw+wEuAy5Nc2q87Cngv8Okkh/fneP7aly1JWldGHSx+Tv/y2CTnAw8FzpvlmAvprjBanf1GrlCSNKi1nkG0qr42RCGSpMm4r88sliRtIAwCSWqcQSBJjTMIJKlxBoEkNc4gkKTGGQSS1DiDQJIaZxBIUuMMAklqnEEgSY0zCCSpcQaBJDXOIJCkxhkEktQ4g0CSGmcQSFLjDAJJapxBIEmNMwgkqXEGgSQ1ziCQpMYZBJLUOINAkhpnEEhS4wwCSWqcQSBJjTMIJKlxBoEkNc4gkKTGGQSS1DiDQJIaZxBIUuMMAklqnEEgSY0bLAiSnJbk5iRXTFm3RZLFSZb3/24+1PtLkkYzZIvgY8AB09a9DVhSVTsBS/plSdIEDRYEVfV14NZpq58NLOpfLwIOHur9JUmjGfcYwdZVdVP/+hfA1mN+f0nSNBMbLK6qAmqm7UmOSLI0ydIVK1aMsTJJasu4g+CXSbYB6P+9eaYdq+qUqlpQVQvmzZs3tgIlqTXjDoJzgIX964XA2WN+f0nSNENePno6cDGwc5IbkxwOvBd4epLlwP79siRpgjYe6sRV9cIZNu031HtKktaedxZLUuMMAklqnEEgSY0zCCSpcQaBJDXOIJCkxhkEktQ4g0CSGmcQSFLjDAJJapxBIEmNMwgkqXEGgSQ1ziCQpMYZBJLUOINAkhpnEEhS4wwCSWqcQSBJjTMIJKlxBoEkNc4gkKTGGQSS1DiDQJIaZxBIUuMMAklqnEEgSY0zCCSpcQaBJDXOIJCkxhkEktQ4g0CSGmcQSFLjDAJJapxBIEmNMwgkqXETCYIkByT5QZJrk7xtEjVIkjpjD4IkGwEfBp4B7Aq8MMmu465DktSZRItgL+Daqrquqv4AfAp49gTqkCQxmSDYFvjplOUb+3WSpAnYeNIFzCTJEcAR/eIdSX4wyXoGthVwy6SLGFX+Y+GkS1ifzKnPDoBjMukK1idz6vPL69f6s9thlJ0mEQQ/Ax4+ZXm7ft29VNUpwCnjKmqSkiytqgWTrkNrz89ubvPz60yia+i7wE5JHpHkAcALgHMmUIckiQm0CKrq7iSvBb4EbAScVlVXjrsOSVJnImMEVfVF4IuTeO/1VBNdYBsoP7u5zc8PSFVNugZJ0gQ5xYQkNc4gGFCSO6a8PjDJD5PskOTYJHcmedgM+1aS909ZflOSY8dWuP4kyTuSXJnksiSXJjkmyXum7bN7kqv715smOTnJj5IsS3JBkidMpvoN39Sfm/tw7AX9VDffT/LdJLuvy9rmEoNgDJLsB5wIPKOqbuhX3wK8cYZD7gKem2SrcdSn1UvyROCZwB5V9Vhgf+B84NBpu74AOL1/fSpwK7BTVe0JvIzuWnWtnw6rqt2Ak4DjJl3MpBgEA0vyZOC/gGdW1Y+mbDoNODTJFqs57G66Qax/GUOJmtk2wC1VdRdAVd1SVV8Hbpv2V/7zgdOTPAp4AnB0Va3sj7m+qr4w7sJbk85xSa5IcnmSQ/v190tyUpJrkixO8sUkh6zmFBczZYaDJH+f5OIk30tyZpJN+/UH9udaluTEJOeO5zsclkEwrAcCZwEHV9U107bdQRcGR85w7IeBw5I8dMD6tGZfBh7ed+mdlOQp/frT6VoBJNkbuLWqlgOPBi6tqnsmU27TngvsDuxG13I7Lsk2/fr5dBNcvgR44gzHH0D3s0rfEj8a2L+q9gCWAm9IsglwMl3Lfk9g3mDfzZgZBMP6I/BN4PAZtp8ILEzykOkbqurXwMeB1w9Xntakqu4A9qSb6mQFcEaSlwJnAIckuR/37hbS5DwJOL2q7qmqXwJfAx7frz+zqlZW1S/ouvam+mSS64F30P3xBbA3XXBclORSYCHdVA27ANdV1fX9fhvM524QDGslXbfBXkmOmr6xqm4H/gd4zQzHf4AuRB48WIVao/4XywVVdQzwWuB5VfVT4HrgKcDz6IIB4Epgt36qdc0NhwGPBBYBH+rXBVhcVbv3X7tW1Ux/zG0QDIKBVdWdwEF03Tyr+890PPBKVnNzX1XdCnyamVsUGlCSnZPsNGXV7sCqwf7TgRPo/kK8EaAfA1oKvDNJ+nPMT3LQGMtu1Tfoxtw2SjIPeDLwHeAi4Hn9WMHWwFOnH1jdzVT/CuydZBfgW8A+SXYESPLgJH8N/AB4ZJL5/aHTLxqYswyCMeh/oR8AHJ3kWdO23QJ8nm48YXXej1edTMqmwKIkVyW5jK674Nh+25l0YwLTuwdeDmwNXJvkCuBjwM1jqbZtnwcuA74PfBV4S98V9Fm6qe6vAj4BfA/41fSDq+p3dD9rb66qFcBL6S4AuIxuIHmXfp9XA+clWQb8ZnXnmou8s1jSBi3JplV1R5It6VoJ+/Qh8eecK3RjCsur6oR1We8krLfPI5CkdeTcJJsBDwD+/b6GQO8VSRb257qE7iqiOc8WgSQ1zjECSWqcQSBJjTMIJKlxBoG0DiT58WyTBI6yjzQJBoEkNc4gULP6u36vSfKxfmK5TybZP8lFSZYn2SvJFknO6p9H8K0kj+2P3TLJl/tnFZxKNy3BqvO+OMl3+ucXnDx9yon+TtUv9PPgX7FqpkxpUgwCtW5HujtKd+m/XkQ3UdmbgKOAdwKX9M8jOIpuIkCAY4ALq+rRdHe1bg+Q5G/oph7Yp6p2B+6hm89mqgOAn1fVblX1t8B5w3170uy8oUytu76qLgdIciWwpKoqyeV00xfvQDexHFX11b4l8Jd0c9k8t1//hSS39efbj27G0u/20w09iP8/xcTlwPuTvA84t6q+MeQ3KM3GIFDr7pryeuWU5ZV0Px9/XMvzBVhUVW+faYeq+mGSPYADgXcnWVJV71rL95HWGbuGpDX7Bn3XTpKn0j2x7NfA1+m6kUjyDGDzfv8ldM8qeFi/bYskO0w9YZK/Au6sqk/QPR5xjzF8H9KMbBFIa3YscFo/C+WddA8pgW7s4PS+O+mbwE8AquqqJEcDX+4fXPNHuudN3DDlnI+he4LWyn77q8bxjUgzca4hSWqcXUOS1DiDQJIaZxBIUuMMAklqnEEgSY0zCCSpcQaBJDXOIJCkxv0fzbwLIdwwIwIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f1c0bc3e590>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# GridSearch to see if optimizing the parameters will improve (lower) the RMSE\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "result_df = pd.DataFrame({'models': names, 'results': results})\n",
    "result_df.columns = ['models', 'accuracy']\n",
    "result_df.sort_values(by='accuracy', ascending=True, inplace=True)\n",
    "print result_df.tail(1)\n",
    "\n",
    "# plot results\n",
    "sns.barplot(x='models', y='accuracy', data=result_df);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# #Regression Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3632, 500)\n",
      "(908, 500)\n"
     ]
    }
   ],
   "source": [
    "# applying linear regression model by giving X as concat matrix and y as stars column\n",
    "names = []\n",
    "params = []\n",
    "results = []\n",
    "# import the class\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "\n",
    "X=vectors\n",
    "y=balanced_y\n",
    "\n",
    "#dividing the data in to training and test dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=.2,random_state =1)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final score (MSE): 0.967331997668\n",
      "Final score (RMSE): 0.983530374553\n",
      "1.0990747124618954\n",
      "{'normalize': True, 'fit_intercept': True}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "# instantiate the model (using the default parameters)\n",
    "import numpy as np\n",
    "lr=LinearRegression()\n",
    "\n",
    "# fit the model with data\n",
    "lr.fit(X_train,y_train)\n",
    "\n",
    "pred = lr.predict(X_test)\n",
    "\n",
    "score = metrics.mean_squared_error(pred,y_test)\n",
    "print(\"Final score (MSE): {}\".format(score))\n",
    "\n",
    "# Measure RMSE error.  RMSE is common for regression.\n",
    "score = np.sqrt(metrics.mean_squared_error(pred,y_test))\n",
    "print(\"Final score (RMSE): {}\".format(score))\n",
    "\n",
    "grid_param = {'fit_intercept': [True, False], \n",
    "    'normalize': [True, False]\n",
    "}\n",
    "reg = LinearRegression()\n",
    "reg_grid = GridSearchCV(estimator=reg,\n",
    "                     param_grid=grid_param,\n",
    "                     scoring='neg_mean_squared_error',\n",
    "                     cv=4,\n",
    "                     n_jobs=-1)\n",
    "reg_grid.fit(X,y)\n",
    "\n",
    "results.append(np.sqrt(-reg_grid.best_score_))\n",
    "params.append(reg_grid.best_params_)\n",
    "names.append('Linear Regression')\n",
    "print results[0]\n",
    "print params[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3591469669454086\n",
      "{'max_features': 0.5, 'max_depth': 8}\n"
     ]
    }
   ],
   "source": [
    "grid_param =  {'max_depth': range(2, 10, 2), 'max_features': [0.25, 0.5, 0.75, 1.0]}\n",
    "reg = DecisionTreeRegressor()\n",
    "reg_grid = GridSearchCV(estimator=reg,\n",
    "                     param_grid=grid_param,\n",
    "                     scoring='neg_mean_squared_error',\n",
    "                     cv=4,\n",
    "                     n_jobs=-1)\n",
    "reg_grid.fit(X,y)\n",
    "\n",
    "results.append(np.sqrt(-reg_grid.best_score_))\n",
    "params.append(reg_grid.best_params_)\n",
    "names.append('DecisionTreeRegressor')\n",
    "print results[1]\n",
    "print params[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0489738977883685\n",
      "{'C': 1000.0, 'gamma': 1.0}\n"
     ]
    }
   ],
   "source": [
    "grid_param = {'C': [1e0, 1e1, 1e2, 1e3], 'gamma': np.logspace(-2, 2, 5)}\n",
    "reg = SVR()\n",
    "reg_grid = GridSearchCV(estimator=reg,\n",
    "                     param_grid=grid_param,\n",
    "                     scoring='neg_mean_squared_error',\n",
    "                     cv=4,\n",
    "                     n_jobs=-1)\n",
    "reg_grid.fit(X,y)\n",
    "\n",
    "results.append(np.sqrt(-reg_grid.best_score_))\n",
    "params.append(reg_grid.best_params_)\n",
    "names.append('SVR')\n",
    "print results[2]\n",
    "print params[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  models      RMSE\n",
      "2    SVR  1.048974\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAGBtJREFUeJzt3Xu4XXV95/H3RwL1gkI1xxnLpYFHrEXuRKRSFAoq0A7UyyhY72jUCh3rFS0FRafVotZRUURFhNqgqKVRo8FaEAdBCQXDRcFMUAk6QxDEUqrcvvPHWmexOZxz9knIOjsneb+eJ0/2Wuu31/7utfbZn3X97VQVkiQBPGTUBUiSNhyGgiSpYyhIkjqGgiSpYyhIkjqGgiSpYyhIkjqGgiSpYyhIkjrzRl3A2po/f34tWLBg1GVI0pxy2WWX3VxVY8Pa9RYKSU4H/gS4qap2mabdk4GLgSOr6gvD5rtgwQKWL1++/gqVpE1Akp/MpF2fh4/OAA6ZrkGSzYD3Auf1WIckaYZ6C4WquhC4ZUizY4EvAjf1VYckaeZGdqI5yTbAs4GPzaDtoiTLkyxfs2ZN/8VJ0iZqlFcffRB4a1XdO6xhVZ1WVQurauHY2NDzJJKkdTTKq48WAmcnAZgPHJbk7qo6d4Q1SdImbWShUFU7jD9OcgbwFQNBkkarz0tSFwMHAPOTrAZOBDYHqKpT+3pdSdK66y0UquqotWj7sr7qkCTNnN1cSJI6c66bi7Wx95vPHHUJm4TLTn7JqEuQtJ64pyBJ6hgKkqSOoSBJ6hgKkqSOoSBJ6hgKkqSOoSBJ6hgKkqSOoSBJ6hgKkqSOoSBJ6hgKkqSOoSBJ6hgKkqSOoSBJ6hgKkqSOoSBJ6hgKkqSOoSBJ6vQWCklOT3JTkqummP5nSVYkuTLJd5Ls3lctkqSZ6XNP4QzgkGmmXw88vap2Bd4FnNZjLZKkGZjX14yr6sIkC6aZ/p2BwUuAbfuqRZI0MxvKOYWjga+NughJ2tT1tqcwU0kOpAmFP5ymzSJgEcD2228/S5VJ0qZnpHsKSXYDPgkcUVW/mKpdVZ1WVQurauHY2NjsFShJm5iRhUKS7YEvAS+uqutGVYck6T69HT5Kshg4AJifZDVwIrA5QFWdCpwAPAb4aBKAu6tqYV/1SJKG6/Pqo6OGTH8l8Mq+Xl+StPY2lKuPJEkbAENBktQxFCRJHUNBktQxFCRJHUNBktQxFCRJHUNBktQxFCRJHUNBktQZedfZ0lR+etKuoy5ho7f9CVeOugRtYNxTkCR1DAVJUsdQkCR1DAVJUsdQkCR1DAVJUsdQkCR1vE9BUi/2+/B+oy5ho3fRsRet93m6pyBJ6hgKkqSOoSBJ6vQWCklOT3JTkqummJ4kH0qyMsmKJHv1VYskaWb63FM4AzhkmumHAju1/xYBH+uxFknSDPQWClV1IXDLNE2OAM6sxiXA1kke11c9kqThRnlOYRvghoHh1e24B0iyKMnyJMvXrFkzK8VJ0qZoTpxorqrTqmphVS0cGxsbdTmStNEaZSjcCGw3MLxtO06SNCKjDIUlwEvaq5D2BW6rqp+PsB5J2uT11s1FksXAAcD8JKuBE4HNAarqVGApcBiwErgDeHlftUiSZqa3UKiqo4ZML+B1fb2+JGntzYkTzZKk2WEoSJI6hoIkqWMoSJI6hoIkqWMoSJI6hoIkqWMoSJI6hoIkqWMoSJI6hoIkqWMoSJI6hoIkqWMoSJI6hoIkqWMoSJI6hoIkqWMoSJI6hoIkqWMoSJI6hoIkqdNrKCQ5JMm1SVYmOW6S6dsnOT/J5UlWJDmsz3okSdPrLRSSbAacAhwK7AwclWTnCc2OBz5fVXsCRwIf7aseSdJwfe4p7AOsrKpVVXUncDZwxIQ2BTyqfbwV8LMe65EkDTGvx3lvA9wwMLwaeMqENu8AzktyLPAI4OAe65EkDTHqE81HAWdU1bbAYcBZSR5QU5JFSZYnWb5mzZpZL1KSNhXThkKSPxp4vMOEac8ZMu8bge0Ghrdtxw06Gvg8QFVdDDwUmD9xRlV1WlUtrKqFY2NjQ15WkrSuhu0pvG/g8RcnTDt+yHMvBXZKskOSLWhOJC+Z0OanwEEASX6fJhTcFZCkERkWCpni8WTD91NVdwPHAMuAH9BcZXR1kpOSHN42eyPwqiTfBxYDL6uqmnH1kqT1atiJ5pri8WTDD3xy1VJg6YRxJww8vgbYb9h8JEmzY1go7JhkCc1ewfhj2uEdpn6aJGkuGhYKg/cVvG/CtInDkqQ5btpQqKpvDQ4n2RzYBbixqm7qszBJ0uwbdknqqUme1D7eCvg+cCZweZKjZqE+SdIsGnb10f5VdXX7+OXAdVW1K7A38JZeK5MkzbphoXDnwONnAOcCVNX/7a0iSdLIDAuFXyb5kyR70lw6+nWAJPOAh/VdnCRpdg27+ujVwIeA/wq8fmAP4SDgq30WJkmafcOuProOOGSS8cto7lSWJG1Epg2FJB+abnpV/cX6LUeSNErDDh+9BriKpifTnzGkvyNJ0tw2LBQeB/x34AXA3cDngC9U1S/7LkySNPumvfqoqn5RVadW1YE09ylsDVyT5MWzUp0kaVbN6Oc4k+xF8ytpzwC+BlzWZ1GSpNEYdqL5JOCPaX4P4Wzgbe3vJEiSNkLD9hSOB64Hdm///U0SaE44V1Xt1m95kqTZNCwU/M0ESdqEDLt57SeTjU/yEJpzDJNOlyTNTcO6zn5Ukrcl+UiSZ6ZxLLAKeP7slChJmi3DDh+dBdwKXAy8Eng7zfmEP62qK3quTZI0y4b+RnP7+wkk+STwc2D7qvp175VJkmbdsK6z7xp/UFX3AKsNBEnaeA0Lhd2T/Kr99+/AbuOPk/xq2MyTHJLk2iQrkxw3RZvnJ7kmydVJ/nFd3oQkaf0YdvXRZus64ySbAafQ3AW9Grg0yZKqumagzU7A24D9qurWJI9d19eTJD14w/YUHox9gJVVtaqq7qS5I/qICW1eBZxSVbcCVNVNPdYjSRqiz1DYBrhhYHh1O27QE4AnJLkoySVJHvCDPgBJFiVZnmT5mjVreipXktRnKMzEPGAn4ACam+E+kWTriY2q6rSqWlhVC8fGxma5REnadPQZCjcC2w0Mb9uOG7QaWFJVd1XV9cB1NCEhSRqBPkPhUmCnJDsk2QI4Elgyoc25NHsJJJlPczhpVY81SZKm0VsotF1sHwMso+l6+/NVdXWSk5Ic3jZbBvwiyTXA+cCbq+oXfdUkSZrejH5kZ11V1VJg6YRxJww8LuAN7T9J0oiN+kSzJGkDYihIkjqGgiSpYyhIkjqGgiSpYyhIkjqGgiSpYyhIkjqGgiSpYyhIkjqGgiSpYyhIkjqGgiSpYyhIkjqGgiSpYyhIkjqGgiSpYyhIkjqGgiSpYyhIkjqGgiSp02soJDkkybVJViY5bpp2z01SSRb2WY8kaXq9hUKSzYBTgEOBnYGjkuw8SbtHAv8D+G5ftUiSZqbPPYV9gJVVtaqq7gTOBo6YpN27gPcCv+6xFknSDPQZCtsANwwMr27HdZLsBWxXVV/tsQ5J0gyN7ERzkocAHwDeOIO2i5IsT7J8zZo1/RcnSZuoPkPhRmC7geFt23HjHgnsAlyQ5MfAvsCSyU42V9VpVbWwqhaOjY31WLIkbdr6DIVLgZ2S7JBkC+BIYMn4xKq6rarmV9WCqloAXAIcXlXLe6xJkjSN3kKhqu4GjgGWAT8APl9VVyc5Kcnhfb2uJGndzetz5lW1FFg6YdwJU7Q9oM9aJEnDeUezJKljKEiSOoaCJKljKEiSOoaCJKljKEiSOoaCJKljKEiSOoaCJKljKEiSOoaCJKljKEiSOoaCJKljKEiSOoaCJKljKEiSOoaCJKljKEiSOoaCJKljKEiSOoaCJKljKEiSOr2GQpJDklybZGWS4yaZ/oYk1yRZkeSbSX63z3okSdPrLRSSbAacAhwK7AwclWTnCc0uBxZW1W7AF4C/66seSdJwfe4p7AOsrKpVVXUncDZwxGCDqjq/qu5oBy8Btu2xHknSEH2GwjbADQPDq9txUzka+NpkE5IsSrI8yfI1a9asxxIlSYM2iBPNSV4ELAROnmx6VZ1WVQurauHY2NjsFidJm5B5Pc77RmC7geFt23H3k+Rg4K+Ap1fVb3qsR5I0RJ97CpcCOyXZIckWwJHAksEGSfYEPg4cXlU39ViLJGkGeguFqrobOAZYBvwA+HxVXZ3kpCSHt81OBrYEzklyRZIlU8xOkjQL+jx8RFUtBZZOGHfCwOOD+3x9SdLa2SBONEuSNgyGgiSpYyhIkjqGgiSpYyhIkjqGgiSpYyhIkjqGgiSpYyhIkjqGgiSpYyhIkjqGgiSpYyhIkjqGgiSpYyhIkjqGgiSpYyhIkjqGgiSpYyhIkjqGgiSpYyhIkjq9hkKSQ5Jcm2RlkuMmmf5bST7XTv9ukgV91iNJml5voZBkM+AU4FBgZ+CoJDtPaHY0cGtVPR74e+C9fdUjSRquzz2FfYCVVbWqqu4EzgaOmNDmCOAz7eMvAAclSY81SZKm0WcobAPcMDC8uh03aZuquhu4DXhMjzVJkqYxb9QFzESSRcCidvD2JNeOsp6ezQduHnURayPve+moS9iQzK31d6I75gPm1roD8hdrtf5+dyaN+gyFG4HtBoa3bcdN1mZ1knnAVsAvJs6oqk4DTuupzg1KkuVVtXDUdWjduP7mLtddo8/DR5cCOyXZIckWwJHAkgltlgDjm5nPA/61qqrHmiRJ0+htT6Gq7k5yDLAM2Aw4vaquTnISsLyqlgCfAs5KshK4hSY4JEkjEjfMNyxJFrWHyzQHuf7mLtddw1CQJHXs5kKS1JlToZDkniRXJLk6yfeTvDHJOr2HJCclOXia6a9J8pJ1mO+z2hqvSHJ7283HFUnOXJc6J5n/6iRXJlmR5Pwk2w1/1tyV5PZJxq3TunmQdVzQrsvvJ7k0yR6z+frDDPs8C5L8VfvdsaL9mzwxyd9OaLNHkh+0j3888Lf2rSQzuqRzrptTh4+S3F5VW7aPHwv8I3BRVZ042soml+QC4E1VtXySafPaG/bWdp6rgV2q6pdJ/ifw6Kp67XqodZ3q6fu1Btf5bGnvqk9V3Tsw7gLadZnk5cALq+oZ6+G1Zm25b8qS/AHwAeCAqvpNkvk03e+cUVU7DrR7D3BHVZ2U5MfAwqq6Ock7gd+pqleNov7ZNKf2FAZV1U00N7Qdk8ZmSU5ut+JWJHn1eNskb20T//vtSifJGUme1z5+T5Jr2ue9rx33jiRvah/vkeSSdvo/JfntdvwFSd6b5HtJrkuy/3Q1J3llknOTnE9zVRZJjmufvyLJCQNtX9qOvyLJR6fYI7qYgbvEp3pOkle39X03ySeTfLAd/w9JPpbke8DfJNmyXS7fS3J5kv/Wttu1Xa5XtHXumOSRSb7WLtOrBpblM9t2Vyb5RJrLkcf3cN6T5HLg2TNe0ZMvx8F1M+k6mOrz0L7Hbyb5t7bGI9rxC9LsCZwJXMX977EZttyfmeTidp7nJBnfcDksyQ+TXJbkQ0m+MlD/WUkuorn6bqpaH5fkwnZ5XpVk/7btGe3wlUn+sm07+Hk+qF1/VyY5PclvteN/nOSdA+/9iQ9mPcwxjwNurqrfAFTVzVV1IXBrkqcMtHs+sHiS599vnW/M5mwoAFTVKprLXR9L07nebVX1ZODJwKvS3CNxKE0fS0+pqt2BvxucR5LH0HxJPamqdgPePclLnQm8tZ1+JTC4ZzKvqvYBXj9h/FT2BJ5TVQclOQzYHngKsAfw1CRPTbJLW9NTq2oPmkuHJ7tc91nAue37mPQ5aQ4vHde+xv40W0eDHgfsW1VvAU4Avt6+nz8C3p/kocCfA+9r5/tk4GfAYcCPq2r3qtoF+EaShwOnA8+tql2Bh3PfnegAN1XVnlV1zgyW09qYbB1M+nkAfg08u6r2Ag5s3+P4baE7AR+tqidV1U+meb1DuG+5zweOBw5u57kceEO73D4OHFpVewNjE+axc/uco6ap9YXAsna57w5cQfM52aaqdmmX8acHZ9q+7hnAC9rp84DBPcmb2zo/Brxpmve4sTkP2K7dcPhokqe34xfT/m0l2Re4pap+NMnzu3W+sZsT3VzM0DOB3ca3lmjujt4JOBj4dFXdAVBVt0x43m00XxSfarfkvjI4MclWwNZV9a121GeAwS+1L7X/XwYsmEGd51XVrQM1Hwpc3g5vCTwB2Jrmy2F5+331MO7fj9S32zD7Jc0XPu37nOw5d9LcFHhr+36+QBNE484ZOEzyTODQ3NfN+UPbtt8Bjk9zTPVLVbUyyQrgPWn2vL5cVRcl2Ru4rqr+T/v8M2m+8D7SDn9uBstnXUy2Dqb6PKym2St6GnAvzdbff2nb/KSqLpnmdT7b7vlsSfPlDLAvzRf8Re1y34Jmq/KJwKqqur5tt5j7B+SSqvrPIbVeCpyeZHPg3Kq6IskqYMckHwa+SvNlN+j3gOur6rp2+DPA64APTrKsnjPNe92oVNXt7edzf5qNgc+1n/PPAd9J8kaacJi4l3B+kkcDtwN/PZs1j8qcDoUkOwL3ADcBAY6tqmUT2jxrunm0N9ntAxxEc1f1MTRbyTP1m/b/e5jZ8vyPwfKAd1fVpwYbtIcETq+qqT6E+7fzWUyzZfyWdl4PeM7AF81M6/nTgS/1cdcluRj4Y+DrSV5RVRcmWUizx/CeJF+jPSQ2w9danyZbB1N9Hl5Gs9W+d1Xdlea48UNnWN+f0XyZngx8mOZLNcA32i3+wdcZdiJ64nJ/QK3tfJ5Gs9zPSPKBqjozye40e4mvoTnc8YohrzVobT+vG42quge4ALggyZXAS6vqjCTXA08Hngv8wYSnHUiz8fVZ4J3AG2av4tGYs4ePkowBpwIfabvGWAa8tt2qIskTkjwC+Abw8vbQBm3qD85nS2CrqloK/CXNbnqnqm6jOe44fr7gxcC3WD+WAUe3dZJk2/ZwxL8Az28fk+QxSQa37qmqu2gOl7wiydbTPOd7wIFJtm6XzXRbh8uAY8cHkuzZ/r9jVa2sqv9Fsye1W5JtgNur6izg/cBewA9oujYZP3H3ItbfslpbU30etqI5jHVXkgOZYSdh49rP2l8D+7bH5C8B9kvy+PZ1HpHkCcC1NFv0C9qnvmBta233zP5fVX0C+CSwV7t+H1JVX6Q5bLXXhHldCywYr4f1+3mds5L8XpKdBkbtAYwfIlxM83suq6pq9cTnthcCvB54ycTvj43RXNtSeFiSK4DNgbuBs2iuKIDmj2YB8G/tMeI1NFu9X2+32pYnuRNYCrx9YJ6PBP65PRYbJt8SeClwahssq4CXr483U1VLx79Y2kMP/05zVcuVaa52+Jc0J4vvotkq/OmE569Ocg7w2qr628meU1WXJjmZ5lDELTRfGrdNUdI7gQ+2W1EPAVbSnI95YZKj2nn+DHgH8FSaPYR7aQ5Rvaaq7khyNPClND+y9F3gEw9yMT08zRVX4z4wZcv7m/TzQLPF9+X2PS4Hfri2BVXVfyZ5P/Dmqjq63ftYnPaELnB8VV2X5M9p9qz+g2b5r22tBwBvTnIXzeGLl9Ac7vp07rvw4G0Tavt1mqujzknTyeSlNBtPm7otgQ+3G1B303y2xw/nnQN8iIENoomq6udJFtMcintXz7WO1Jy6JFXrJsmW7THVzYF/Bj5WVV8edV0bu4HlHppfIfxRVf39qOuSpjNnDx9prbwrzaWgK2j2FL4ypL3Wj1e1e7ZX0xy2+viI65GGck9BktRxT0GS1DEUJEkdQ0GS1DEUpPUsTR9D8x9sG2kUDAVJUsdQkOh6Sf1hmt5Gr0vy2SQHJ7koyY+S7JPk0Wl6uV2Rptfc3drnPibJeWn66v8kzU2Q4/N9Ue7rufbj7U19g6/7iCRfzX29zU5357PUO0NBus/jabrseGL774XAH9L0Jvp2mju+L297y307TYd/0PQ/9b+r6knAP9F2OJjk92m6t9iv7en0Hpr+kwYdAvxsoLfZr/f39qTh5lo3F1Kfrq+qKwGSXA18s6qq7RJjAU0/Sc8FqKp/bfcQHgU8jbZPqar6apLxXnAPAvYGLs19PdfeNOE1r6Tpvvu9wFeq6tt9vkFpGENBus9vBh7fOzB8L83fyl1rOb8An6mqt03VoO0jaS+a3mbfneSbVXXSWr6OtN54+EiauW/THv5JcgDND9b8CriQ5lATaX7U6bfb9t8Enpfmp2Npz0ncr1fWJL9D8/OP/0DTJffEXk+lWeWegjRz76D50ZsVwB00vedCc65hcXvI6Tu0vdlW1TVJjgfOG+i59nXc12UzwK7AyW1vs3dx/19Jk2adfR9JkjoePpIkdQwFSVLHUJAkdQwFSVLHUJAkdQwFSVLHUJAkdQwFSVLn/wOmqefbU8eTtgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f1c0bb83f50>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# GridSearch to see if optimizing the parameters will improve (lower) the RMSE\n",
    "result_df = pd.DataFrame({'models': names, 'results': results})\n",
    "result_df.columns = ['models', 'RMSE']\n",
    "result_df.sort_values(by='RMSE', ascending=False, inplace=True)\n",
    "print result_df.tail(1)\n",
    "\n",
    "# plot results\n",
    "sns.barplot(x='models', y='RMSE', data=result_df);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remodeling our Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As our final task, we’ll try to model a simpler problem and run the exact same analysis. Instead of trying to predict the exact star rating, we’ll try to classify the posts into positive ( 5-star reviews) or negative (1 star reviews). We’ll remove all the 3-star reviews for this task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep = set([1,5])\n",
    " \n",
    "# calculate the indices for the examples we want to keep\n",
    "keep_train_is = [i for i, y in enumerate(y_train) if y in keep]\n",
    "keep_test_is = [i for i, y in enumerate(y_test) if y in keep]\n",
    " \n",
    "# convert the train set\n",
    "X_train2 = X_train[keep_train_is, :]\n",
    "y_train2 = [y_train[i] for i in keep_train_is]\n",
    "y_train2 = [\"n\" if (y == 1 ) else \"p\" for y in y_train2]\n",
    " \n",
    "# convert the test set\n",
    "X_test2 = X_test[keep_test_is, :]\n",
    "y_test2 = [y_test[i] for i in keep_test_is]\n",
    "y_test2 = [\"n\" if (y == 1) else \"p\" for y in y_test2]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
